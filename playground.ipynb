{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e7d7a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install spotipy -q\n",
    "!pip install streamlit -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60d7fd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyOAuth, SpotifyClientCredentials\n",
    "import yaml\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle\n",
    "import streamlit as st\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8eb93eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the configs.yaml file\n",
    "with open('configs.yaml', 'r') as file:\n",
    "    config_data = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0bf7d89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'track_uri': 'object',\n",
       " 'artist_uri': 'object',\n",
       " 'album_uri': 'object',\n",
       " 'danceability': 'float16',\n",
       " 'energy': 'float16',\n",
       " 'key': 'float16',\n",
       " 'loudness': 'float16',\n",
       " 'mode': 'float16',\n",
       " 'speechiness': 'float16',\n",
       " 'acousticness': 'float16',\n",
       " 'instrumentalness': 'float16',\n",
       " 'liveness': 'float16',\n",
       " 'valence': 'float16',\n",
       " 'tempo': 'float16',\n",
       " 'duration_ms': 'float32',\n",
       " 'time_signature': 'float16',\n",
       " 'Track_release_date': 'int8',\n",
       " 'Track_pop': 'int8',\n",
       " 'Artist_pop': 'int8',\n",
       " 'Artist_genres': 'object'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_data[\"datatypes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f353a7aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'album_uri'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_data[\"column_names\"][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72760a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_track_IDs(user, playlist_id, sp_client, log):\n",
    "    \"\"\"\n",
    "    returns track ids for the playlist\n",
    "    \"\"\"\n",
    "    try:\n",
    "        log.append('Start playlist extraction')\n",
    "        track_ids = []\n",
    "        playlist = sp_client.user_playlist(user, playlist_id)\n",
    "        for item in playlist['tracks']['items']:\n",
    "            track = item['track']\n",
    "            track_ids.append(track['id'])\n",
    "        return track_ids, log\n",
    "    except Exception as e:\n",
    "        log.append('Failed to load the playlist')\n",
    "        log.append(e)\n",
    "\n",
    "def get_track_and_artist_IDs(user, playlist_id, sp_client, log):\n",
    "    \"\"\"\n",
    "    returns track ids, artists for the playlist\n",
    "    \"\"\"\n",
    "    try:\n",
    "        log.append('Start playlist extraction')\n",
    "        track_ids = []\n",
    "        artist_id = []\n",
    "        playlist = sp_client.user_playlist(user, playlist_id)\n",
    "        for item in playlist['tracks']['items']:\n",
    "            track = item['track']\n",
    "            track_ids.append(track['id'])\n",
    "            artist = item['track']['artists']\n",
    "            artist_id.append(artist[0]['id'])\n",
    "        return track_ids, artist_id, log\n",
    "    except Exception as e:\n",
    "        log.append('Failed to load the playlist')\n",
    "        log.append(e)\n",
    "def extract_features(track_ids_uni, artist_id_uni, sp_client):\n",
    "    \"\"\"\n",
    "    extracts \n",
    "        1. audio features\n",
    "        2. track features\n",
    "        3. artists features\n",
    "    \"\"\"\n",
    "    err = []\n",
    "    err.append('Start audio features extraction')\n",
    "    audio_features = pd.DataFrame()\n",
    "    for i in range(0, len(track_ids_uni), 25):\n",
    "        try:\n",
    "            track_feature = sp.audio_features(track_ids_uni[i:i+25])\n",
    "            track_df = pd.DataFrame(track_feature)\n",
    "            audio_features = pd.concat([audio_features, track_df], axis=0)\n",
    "        except Exception as e:\n",
    "            err.append(e)\n",
    "            continue\n",
    "    err.append('Start track features extraction new')\n",
    "    # keeping a divisor of 5 as length of track id list\n",
    "    if len(track_ids_uni)%5==0: pass\n",
    "    else:\n",
    "        rem = len(track_ids_uni)%5\n",
    "        track_ids_uni = track_ids_uni[:-rem]\n",
    "    track_ = pd.DataFrame()\n",
    "    for i in range(0, len(track_ids_uni), 5):\n",
    "        try:\n",
    "            track_features = sp.tracks(track_ids_uni[i:i+5])\n",
    "            for x in range(5):\n",
    "                track_pop = pd.DataFrame([track_ids_uni[i+x]], columns=['Track_uri'])\n",
    "                track_pop['Track_release_date'] = track_features['tracks'][x]['album']['release_date']\n",
    "                track_pop['Track_pop'] = track_features['tracks'][x][\"popularity\"]\n",
    "                track_pop['Artist_uri'] = track_features['tracks'][x]['artists'][0]['id']\n",
    "                track_pop['Album_uri'] = track_features['tracks'][x]['album']['id']\n",
    "                track_ = pd.concat([track_, track_pop], axis=0)\n",
    "        except Exception as e:\n",
    "            err.append(e)\n",
    "            continue\n",
    "    err.append('Start artist features extraction')\n",
    "    # keeping a divisor of 5 as length of artist id list\n",
    "    if len(artist_id_uni)%5==0: pass\n",
    "    else:\n",
    "        rem = len(artist_id_uni)%5\n",
    "        artist_id_uni = artist_id_uni[:-rem]\n",
    "    artist_ = pd.DataFrame()\n",
    "    for i in range(0, len(artist_id_uni), 5):\n",
    "        try:\n",
    "            artist_features = sp.artists(artist_id_uni[i:i+5])\n",
    "            for x in range(5):\n",
    "                artist_df = pd.DataFrame([artist_id_uni[i+x]], columns=['Artist_uri'])\n",
    "                artist_pop = artist_features['artists'][x][\"popularity\"]\n",
    "                artist_genres = artist_features['artists'][x][\"genres\"]\n",
    "                artist_df[\"Artist_pop\"] = artist_pop\n",
    "                if artist_genres:\n",
    "                    artist_df[\"genres\"] = \" \".join([re.sub(' ', '_', i) for i in artist_genres])\n",
    "                else:\n",
    "                    artist_df[\"genres\"] = \"unknown\"\n",
    "                artist_ = pd.concat([artist_, artist_df], axis=0)\n",
    "        except Exception as e:\n",
    "            err.append(e)\n",
    "            continue\n",
    "    # bring all the features together\n",
    "    try:\n",
    "        test = pd.DataFrame(\n",
    "            track_, columns=['Track_uri', 'Artist_uri', 'Album_uri'])\n",
    "\n",
    "        test.rename(columns={'Track_uri': 'track_uri',\n",
    "                    'Artist_uri': 'artist_uri', 'Album_uri': 'album_uri'}, inplace=True)\n",
    "\n",
    "        audio_features.drop(\n",
    "            columns=['type', 'uri', 'track_href', 'analysis_url'], axis=1, inplace=True)\n",
    "\n",
    "        test = pd.merge(test, audio_features,\n",
    "                        left_on=\"track_uri\", right_on=\"id\", how='outer')\n",
    "        test = pd.merge(test, track_, left_on=\"track_uri\",\n",
    "                        right_on=\"Track_uri\", how='outer')\n",
    "        test = pd.merge(test, artist_, left_on=\"artist_uri\",\n",
    "                        right_on=\"Artist_uri\", how='outer')\n",
    "\n",
    "        test.rename(columns={'genres': 'Artist_genres'}, inplace=True)\n",
    "\n",
    "        test.drop(columns=['Track_uri', 'Artist_uri_x',\n",
    "                'Artist_uri_y', 'Album_uri', 'id'], axis=1, inplace=True)\n",
    "\n",
    "        test.dropna(axis=0, inplace=True)\n",
    "        test['Track_pop'] = test['Track_pop'].apply(lambda x: int(x/5))\n",
    "        test['Artist_pop'] = test['Artist_pop'].apply(lambda x: int(x/5))\n",
    "        test['Track_release_date'] = test['Track_release_date'].apply(lambda x: x.split('-')[0])\n",
    "        test['Track_release_date'] = test['Track_release_date'].astype('int16')\n",
    "        test['Track_release_date'] = test['Track_release_date'].apply(lambda x: int(x/50))\n",
    "\n",
    "        test[['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'time_signature']] = test[[\n",
    "            'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'time_signature']].astype('float16')\n",
    "        test[['duration_ms']] = test[['duration_ms']].astype('float32')\n",
    "        test[['Track_release_date', 'Track_pop', 'Artist_pop']] = test[[\n",
    "            'Track_release_date', 'Track_pop', 'Artist_pop']].astype('int8')\n",
    "    except Exception as e:\n",
    "        err.append(e)\n",
    "    err.append('Finish extraction')\n",
    "    return test, err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1333d3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def playlist_model(url, model, max_gen=3, same_art=5):\n",
    "    log = []\n",
    "    Fresult = []\n",
    "    try:\n",
    "        log.append('Start logging')\n",
    "        uri = url.split('/')[-1].split('?')[0]\n",
    "        try:\n",
    "            log.append('spotify local method')\n",
    "            stream = open(\"credentials.yaml\")\n",
    "            spotify_details = yaml.safe_load(stream)\n",
    "            auth_manager = SpotifyClientCredentials(client_id=spotify_details['client_id'], client_secret=spotify_details['client_secret'])\n",
    "        except:\n",
    "            log.append('spotify .streamlit method')\n",
    "            try:\n",
    "                client_id=st.secrets[\"client_id\"]\n",
    "                client_secret=st.secrets[\"client_secret\"]\n",
    "                auth_manager = SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)\n",
    "            except:\n",
    "                log.append('spotify hug method')\n",
    "                client_id=os.environ['client_id']\n",
    "                client_secret=os.environ['client_secret']\n",
    "                auth_manager = SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)\n",
    "        \n",
    "        sp = spotipy.client.Spotify(auth_manager=auth_manager) \n",
    "\n",
    "        if model == 'Spotify Model':\n",
    "            track_ids, log = get_track_IDs('Sushant', uri, sp, log)\n",
    "            track_ids_uni = list(set(track_ids))\n",
    "            log.append('Starting Spotify Model')\n",
    "            spotifyresult = pd.DataFrame()\n",
    "            for i in range(len(track_ids_uni)-5):\n",
    "                if len(spotifyresult) >= 50:\n",
    "                    break\n",
    "                try:\n",
    "                    ff = sp.recommendations(seed_tracks=list(track_ids_uni[i:i+5]), limit=5)\n",
    "                except Exception as e:\n",
    "                    log.append(e)\n",
    "                    continue\n",
    "                for z in range(5):\n",
    "                    result = pd.DataFrame([z+(5*i)+1])\n",
    "                    result['uri'] = ff['tracks'][z]['id']\n",
    "                    spotifyresult = pd.concat([spotifyresult, result], axis=0)\n",
    "                    spotifyresult.drop_duplicates(subset=['uri'], inplace=True,keep='first')\n",
    "                Fresult = spotifyresult.uri[:50]\n",
    "\n",
    "            log.append('Model run successfully')\n",
    "            return Fresult, log\n",
    "\n",
    "        lendf=len(pd.read_csv('Data/streamlit.csv',usecols=['track_uri']))\n",
    "        dtypes = {'track_uri': 'object', 'artist_uri': 'object', 'album_uri': 'object', 'danceability': 'float16', 'energy': 'float16', 'key': 'float16',\n",
    "                'loudness': 'float16', 'mode': 'float16', 'speechiness': 'float16', 'acousticness': 'float16', 'instrumentalness': 'float16',\n",
    "                'liveness': 'float16', 'valence': 'float16', 'tempo': 'float16', 'duration_ms': 'float32', 'time_signature': 'float16',\n",
    "                'Track_release_date': 'int8', 'Track_pop': 'int8', 'Artist_pop': 'int8', 'Artist_genres': 'object'}\n",
    "        col_name= ['track_uri', 'artist_uri', 'album_uri', 'danceability', 'energy', 'key',\n",
    "                'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness',\n",
    "                'liveness', 'valence', 'tempo', 'duration_ms', 'time_signature',\n",
    "                'Track_release_date', 'Track_pop', 'Artist_pop', 'Artist_genres']\n",
    "        \n",
    "        track_ids, artist_id, log = get_track_and_artist_IDs('Sushant', uri, sp, log)\n",
    "        log.append(\"Number of unique tracks : {}\".format(len(track_ids)))\n",
    "        log.append(\"Number of unique artists : {}\".format(len(artist_id)))\n",
    "        \n",
    "        artist_id_uni = list(set(artist_id))\n",
    "        track_ids_uni = list(set(track_ids))\n",
    "        \n",
    "        log.append(\"Number of unique artists : {}\".format(len(artist_id_uni)))\n",
    "        log.append(\"Number of unique tracks : {}\".format(len(track_ids_uni)))\n",
    "\n",
    "        test, err = extract_features(track_ids_uni, artist_id_uni, sp)\n",
    "        for i in err:\n",
    "            log.append(i)\n",
    "        del err\n",
    "        grow = test.copy()\n",
    "        test['Artist_genres'] = test['Artist_genres'].apply(lambda x: x.split(\" \"))\n",
    "        tfidf = TfidfVectorizer(max_features=max_gen)  \n",
    "        tfidf_matrix = tfidf.fit_transform(test['Artist_genres'].apply(lambda x: \" \".join(x)))\n",
    "        genre_df = pd.DataFrame(tfidf_matrix.toarray())\n",
    "        genre_df.columns = ['genre' + \"|\" +i for i in tfidf.get_feature_names()]\n",
    "        genre_df = genre_df.astype('float16')\n",
    "        test.drop(columns=['Artist_genres'], axis=1, inplace=True)\n",
    "        test = pd.concat([test.reset_index(drop=True),genre_df.reset_index(drop=True)], axis=1)\n",
    "        Fresult = pd.DataFrame()\n",
    "        x = 1\n",
    "        for i in range(int(lendf/2), lendf+1, int(lendf/2)):\n",
    "            try:\n",
    "                df = pd.read_csv('Data/streamlit.csv',names= col_name,dtype=dtypes,skiprows=x,nrows=i)\n",
    "                log.append('reading data frame chunks from {} to {}'.format(x,i))\n",
    "            except Exception as e:\n",
    "                log.append('Failed to load grow')\n",
    "                log.append(e)\n",
    "            grow = grow[~grow['track_uri'].isin(df['track_uri'].values)]\n",
    "            df = df[~df['track_uri'].isin(test['track_uri'].values)]\n",
    "            df['Artist_genres'] = df['Artist_genres'].apply(lambda x: x.split(\" \"))\n",
    "            tfidf_matrix = tfidf.transform(df['Artist_genres'].apply(lambda x: \" \".join(x)))\n",
    "            genre_df = pd.DataFrame(tfidf_matrix.toarray())\n",
    "            genre_df.columns = ['genre' + \"|\" +i for i in tfidf.get_feature_names()]\n",
    "            genre_df = genre_df.astype('float16')\n",
    "            df.drop(columns=['Artist_genres'], axis=1, inplace=True)\n",
    "            df = pd.concat([df.reset_index(drop=True),\n",
    "                        genre_df.reset_index(drop=True)], axis=1)\n",
    "            del genre_df\n",
    "            try:\n",
    "                df.drop(columns=['genre|unknown'], axis=1, inplace=True)\n",
    "                test.drop(columns=['genre|unknown'], axis=1, inplace=True)\n",
    "            except:\n",
    "                log.append('genre|unknown not found')\n",
    "            log.append('Scaling the data .....')\n",
    "            if x == 1:\n",
    "                sc = pickle.load(open('Data/sc.sav','rb'))\n",
    "                df.iloc[:, 3:19] = sc.transform(df.iloc[:, 3:19])\n",
    "                test.iloc[:, 3:19] = sc.transform(test.iloc[:, 3:19])\n",
    "                log.append(\"Creating playlist vector\")\n",
    "                playvec = pd.DataFrame(test.sum(axis=0)).T\n",
    "            else:\n",
    "                df.iloc[:, 3:19] = sc.transform(df.iloc[:, 3:19])\n",
    "            x = i\n",
    "            if model == 'Model 1':\n",
    "                df['sim']=cosine_similarity(df.drop(['track_uri', 'artist_uri', 'album_uri'], axis = 1),playvec.drop(['track_uri', 'artist_uri', 'album_uri'], axis = 1))\n",
    "                df['sim2']=cosine_similarity(df.iloc[:,16:-1],playvec.iloc[:,16:])\n",
    "                df['sim3']=cosine_similarity(df.iloc[:,19:-2],playvec.iloc[:,19:])\n",
    "                df = df.sort_values(['sim3','sim2','sim'],ascending = False,kind='stable').groupby('artist_uri').head(same_art).head(50)\n",
    "                Fresult = pd.concat([Fresult, df], axis=0)\n",
    "                Fresult = Fresult.sort_values(['sim3', 'sim2', 'sim'],ascending=False,kind='stable')\n",
    "                Fresult.drop_duplicates(subset=['track_uri'], inplace=True,keep='first')\n",
    "                Fresult = Fresult.groupby('artist_uri').head(same_art).head(50)\n",
    "            elif model == 'Model 2':\n",
    "                df['sim'] = cosine_similarity(df.iloc[:, 3:16], playvec.iloc[:, 3:16])\n",
    "                df['sim2'] = cosine_similarity(df.loc[:, df.columns.str.startswith('T') | df.columns.str.startswith('A')], playvec.loc[:, playvec.columns.str.startswith('T') | playvec.columns.str.startswith('A')])\n",
    "                df['sim3'] = cosine_similarity(df.loc[:, df.columns.str.startswith('genre')], playvec.loc[:, playvec.columns.str.startswith('genre')])\n",
    "                df['sim4'] = (df['sim']+df['sim2']+df['sim3'])/3\n",
    "                df = df.sort_values(['sim4'], ascending=False,kind='stable').groupby('artist_uri').head(same_art).head(50)\n",
    "                Fresult = pd.concat([Fresult, df], axis=0)\n",
    "                Fresult = Fresult.sort_values(['sim4'], ascending=False,kind='stable')\n",
    "                Fresult.drop_duplicates(subset=['track_uri'], inplace=True,keep='first')\n",
    "                Fresult = Fresult.groupby('artist_uri').head(same_art).head(50)\n",
    "        del test\n",
    "        try:\n",
    "            del df\n",
    "            log.append('Getting Result')\n",
    "        except:\n",
    "            log.append('Getting Result')\n",
    "        if model == 'Model 1':\n",
    "            Fresult = Fresult.sort_values(['sim3', 'sim2', 'sim'],ascending=False,kind='stable')\n",
    "            Fresult.drop_duplicates(subset=['track_uri'], inplace=True,keep='first')\n",
    "            Fresult = Fresult.groupby('artist_uri').head(same_art).track_uri.head(50)\n",
    "        elif model == 'Model 2':\n",
    "            Fresult = Fresult.sort_values(['sim4'], ascending=False,kind='stable')\n",
    "            Fresult.drop_duplicates(subset=['track_uri'], inplace=True,keep='first')\n",
    "            Fresult = Fresult.groupby('artist_uri').head(same_art).track_uri.head(50)\n",
    "        log.append('{} New Tracks Found'.format(len(grow)))\n",
    "        if(len(grow)>=1):\n",
    "            try:\n",
    "                new=pd.read_csv('Data/new_tracks.csv',dtype=dtypes)\n",
    "                new=pd.concat([new, grow], axis=0)\n",
    "                new=new[new.Track_pop >0]\n",
    "                new.drop_duplicates(subset=['track_uri'], inplace=True,keep='last')\n",
    "                new.to_csv('Data/new_tracks.csv',index=False)\n",
    "            except:\n",
    "                grow.to_csv('Data/new_tracks.csv', index=False)\n",
    "        log.append('Model run successfully')\n",
    "    except Exception as e:\n",
    "        log.append(\"Model Failed\")\n",
    "        log.append(e)\n",
    "    return Fresult, log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ce3346",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43407f67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54eeb1e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64060ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def top_tracks(url,region):\n",
    "    log = []\n",
    "    Fresult = []\n",
    "    uri = url.split('/')[-1].split('?')[0]\n",
    "    try:\n",
    "        log.append('spotify local method')\n",
    "        stream = open(\"Spotify/Spotify.yaml\")\n",
    "        spotify_details = yaml.safe_load(stream)\n",
    "        auth_manager = SpotifyClientCredentials(client_id=spotify_details['client_id'], client_secret=spotify_details['client_secret'])\n",
    "    except:\n",
    "        log.append('spotify .streamlit method')\n",
    "        try:\n",
    "            client_id=st.secrets[\"client_id\"]\n",
    "            client_secret=st.secrets[\"client_secret\"]\n",
    "            auth_manager = SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)\n",
    "        except:\n",
    "            log.append('spotify hug method')\n",
    "            client_id=os.environ['client_id']\n",
    "            client_secret=os.environ['client_secret']\n",
    "            auth_manager = SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)\n",
    "    sp = spotipy.client.Spotify(auth_manager=auth_manager)\n",
    "    try:\n",
    "        log.append('Starting Spotify Model')\n",
    "        top=sp.artist_top_tracks(uri,country=region)\n",
    "        for i in range(10) :\n",
    "            Fresult.append(top['tracks'][i]['id'])\n",
    "        log.append('Model run successfully')\n",
    "    except Exception as e:\n",
    "        log.append(\"Model Failed\")\n",
    "        log.append(e)\n",
    "    return Fresult,log\n",
    "\n",
    "def song_model(url, model, max_gen=3, same_art=5):\n",
    "    log = []\n",
    "    Fresult = []\n",
    "    try:\n",
    "     log.append('Start logging')\n",
    "     uri = url.split('/')[-1].split('?')[0]\n",
    "     try:\n",
    "        log.append('spotify local method')\n",
    "        stream = open(\"Spotify/Spotify.yaml\")\n",
    "        spotify_details = yaml.safe_load(stream)\n",
    "        auth_manager = SpotifyClientCredentials(client_id=spotify_details['client_id'], client_secret=spotify_details['client_secret'])\n",
    "     except:\n",
    "        log.append('spotify .streamlit method')\n",
    "        try:\n",
    "            client_id=st.secrets[\"client_id\"]\n",
    "            client_secret=st.secrets[\"client_secret\"]\n",
    "            auth_manager = SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)\n",
    "        except:\n",
    "            log.append('spotify hug method')\n",
    "            client_id=os.environ['client_id']\n",
    "            client_secret=os.environ['client_secret']\n",
    "            auth_manager = SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)\n",
    "     sp = spotipy.client.Spotify(auth_manager=auth_manager)\n",
    "\n",
    "     if model == 'Spotify Model':\n",
    "        log.append('Starting Spotify Model')\n",
    "        aa=sp.recommendations(seed_tracks=[uri], limit=25)\n",
    "        for i in range(25):\n",
    "            Fresult.append(aa['tracks'][i]['id'])\n",
    "        log.append('Model run successfully')\n",
    "        return Fresult, log\n",
    "     lendf=len(pd.read_csv('Data/streamlit.csv',usecols=['track_uri']))\n",
    "     dtypes = {'track_uri': 'object', 'artist_uri': 'object', 'album_uri': 'object', 'danceability': 'float16', 'energy': 'float16', 'key': 'float16',\n",
    "               'loudness': 'float16', 'mode': 'float16', 'speechiness': 'float16', 'acousticness': 'float16', 'instrumentalness': 'float16',\n",
    "               'liveness': 'float16', 'valence': 'float16', 'tempo': 'float16', 'duration_ms': 'float32', 'time_signature': 'float16',\n",
    "               'Track_release_date': 'int8', 'Track_pop': 'int8', 'Artist_pop': 'int8', 'Artist_genres': 'object'}\n",
    "     col_name= ['track_uri', 'artist_uri', 'album_uri', 'danceability', 'energy', 'key',\n",
    "        'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness',\n",
    "        'liveness', 'valence', 'tempo', 'duration_ms', 'time_signature',\n",
    "        'Track_release_date', 'Track_pop', 'Artist_pop', 'Artist_genres']\n",
    "     log.append('Start audio features extraction')\n",
    "     audio_features = pd.DataFrame(sp.audio_features([uri]))\n",
    "     log.append('Start track features extraction')\n",
    "     track_ = pd.DataFrame()\n",
    "     track_features = sp.tracks([uri])\n",
    "     track_pop = pd.DataFrame([uri], columns=['Track_uri'])\n",
    "     track_pop['Track_release_date'] = track_features['tracks'][0]['album']['release_date']\n",
    "     track_pop['Track_pop'] = track_features['tracks'][0][\"popularity\"]\n",
    "     track_pop['Artist_uri'] = track_features['tracks'][0]['artists'][0]['id']\n",
    "     track_pop['Album_uri'] = track_features['tracks'][0]['album']['id']\n",
    "     track_ = pd.concat([track_, track_pop], axis=0)\n",
    "     log.append('Start artist features extraction')\n",
    "     artist_id_uni=list(track_['Artist_uri'])\n",
    "     artist_ = pd.DataFrame()\n",
    "     artist_features = sp.artists(artist_id_uni)\n",
    "     artist_df = pd.DataFrame(artist_id_uni, columns=['Artist_uri'])\n",
    "     artist_pop = artist_features['artists'][0][\"popularity\"]\n",
    "     artist_genres = artist_features['artists'][0][\"genres\"]\n",
    "     artist_df[\"Artist_pop\"] = artist_pop\n",
    "     if artist_genres:\n",
    "        artist_df[\"genres\"] = \" \".join([re.sub(' ', '_', i) for i in artist_genres])\n",
    "     else:\n",
    "        artist_df[\"genres\"] = \"unknown\"\n",
    "     artist_ = pd.concat([artist_, artist_df], axis=0)\n",
    "     try:\n",
    "        test = pd.DataFrame(track_, columns=['Track_uri', 'Artist_uri', 'Album_uri'])\n",
    "        test.rename(columns={'Track_uri': 'track_uri','Artist_uri': 'artist_uri', 'Album_uri': 'album_uri'}, inplace=True)\n",
    "        audio_features.drop(columns=['type', 'uri', 'track_href', 'analysis_url'], axis=1, inplace=True)\n",
    "        test = pd.merge(test, audio_features,left_on=\"track_uri\", right_on=\"id\", how='outer')\n",
    "        test = pd.merge(test, track_, left_on=\"track_uri\",right_on=\"Track_uri\", how='outer')\n",
    "        test = pd.merge(test, artist_, left_on=\"artist_uri\",right_on=\"Artist_uri\", how='outer')\n",
    "        test.rename(columns={'genres': 'Artist_genres'}, inplace=True)\n",
    "        test.drop(columns=['Track_uri', 'Artist_uri_x','Artist_uri_y', 'Album_uri', 'id'], axis=1, inplace=True)\n",
    "        test.dropna(axis=0, inplace=True)\n",
    "        test['Track_pop'] = test['Track_pop'].apply(lambda x: int(x/5))\n",
    "        test['Artist_pop'] = test['Artist_pop'].apply(lambda x: int(x/5))\n",
    "        test['Track_release_date'] = test['Track_release_date'].apply(lambda x: x.split('-')[0])\n",
    "        test['Track_release_date'] = test['Track_release_date'].astype('int16')\n",
    "        test['Track_release_date'] = test['Track_release_date'].apply(lambda x: int(x/50))\n",
    "        test[['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'time_signature']] = test[['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'time_signature']].astype('float16')\n",
    "        test[['duration_ms']] = test[['duration_ms']].astype('float32')\n",
    "        test[['Track_release_date', 'Track_pop', 'Artist_pop']] = test[['Track_release_date', 'Track_pop', 'Artist_pop']].astype('int8')\n",
    "     except Exception as e:\n",
    "        log.append(e)\n",
    "     log.append('Finish extraction')\n",
    "     grow = test.copy()\n",
    "     test['Artist_genres'] = test['Artist_genres'].apply(lambda x: x.split(\" \"))\n",
    "     tfidf = TfidfVectorizer(max_features=max_gen)  \n",
    "     tfidf_matrix = tfidf.fit_transform(test['Artist_genres'].apply(lambda x: \" \".join(x)))\n",
    "     genre_df = pd.DataFrame(tfidf_matrix.toarray())\n",
    "     genre_df.columns = ['genre' + \"|\" +i for i in tfidf.get_feature_names()]\n",
    "     genre_df = genre_df.astype('float16')\n",
    "     test.drop(columns=['Artist_genres'], axis=1, inplace=True)\n",
    "     test = pd.concat([test.reset_index(drop=True),genre_df.reset_index(drop=True)], axis=1)\n",
    "     Fresult = pd.DataFrame()\n",
    "     x = 1\n",
    "     for i in range(int(lendf/2), lendf+1, int(lendf/2)):\n",
    "         try:\n",
    "             df = pd.read_csv('Data/streamlit.csv',names= col_name,dtype=dtypes,skiprows=x,nrows=i)\n",
    "             log.append('reading data frame chunks from {} to {}'.format(x,i))\n",
    "         except Exception as e:\n",
    "             log.append('Failed to load grow')\n",
    "             log.append(e)\n",
    "         grow = grow[~grow['track_uri'].isin(df['track_uri'].values)]\n",
    "         df = df[~df['track_uri'].isin(test['track_uri'].values)]\n",
    "         df['Artist_genres'] = df['Artist_genres'].apply(lambda x: x.split(\" \"))\n",
    "         tfidf_matrix = tfidf.transform(df['Artist_genres'].apply(lambda x: \" \".join(x)))\n",
    "         genre_df = pd.DataFrame(tfidf_matrix.toarray())\n",
    "         genre_df.columns = ['genre' + \"|\" +i for i in tfidf.get_feature_names()]\n",
    "         genre_df = genre_df.astype('float16')\n",
    "         df.drop(columns=['Artist_genres'], axis=1, inplace=True)\n",
    "         df = pd.concat([df.reset_index(drop=True),\n",
    "                        genre_df.reset_index(drop=True)], axis=1)\n",
    "         del genre_df\n",
    "         try:\n",
    "             df.drop(columns=['genre|unknown'], axis=1, inplace=True)\n",
    "             test.drop(columns=['genre|unknown'], axis=1, inplace=True)\n",
    "         except:\n",
    "             log.append('genre|unknown not found')\n",
    "         log.append('Scaling the data .....')\n",
    "         if x == 1:\n",
    "             sc = pickle.load(open('Data/sc.sav','rb'))\n",
    "             df.iloc[:, 3:19] = sc.transform(df.iloc[:, 3:19])\n",
    "             test.iloc[:, 3:19] = sc.transform(test.iloc[:, 3:19])\n",
    "             log.append(\"Creating playlist vector\")\n",
    "             playvec = pd.DataFrame(test.sum(axis=0)).T\n",
    "         else:\n",
    "             df.iloc[:, 3:19] = sc.transform(df.iloc[:, 3:19])\n",
    "         x = i\n",
    "         if model == 'Model 1':\n",
    "             df['sim']=cosine_similarity(df.drop(['track_uri', 'artist_uri', 'album_uri'], axis = 1),playvec.drop(['track_uri', 'artist_uri', 'album_uri'], axis = 1))\n",
    "             df['sim2']=cosine_similarity(df.iloc[:,16:-1],playvec.iloc[:,16:])\n",
    "             df['sim3']=cosine_similarity(df.iloc[:,19:-2],playvec.iloc[:,19:])\n",
    "             df = df.sort_values(['sim3','sim2','sim'],ascending = False,kind='stable').groupby('artist_uri').head(same_art).head(50)\n",
    "             Fresult = pd.concat([Fresult, df], axis=0)\n",
    "             Fresult = Fresult.sort_values(['sim3', 'sim2', 'sim'],ascending=False,kind='stable')\n",
    "             Fresult.drop_duplicates(subset=['track_uri'], inplace=True,keep='first')\n",
    "             Fresult = Fresult.groupby('artist_uri').head(same_art).head(50)\n",
    "         elif model == 'Model 2':\n",
    "             df['sim'] = cosine_similarity(df.iloc[:, 3:16], playvec.iloc[:, 3:16])\n",
    "             df['sim2'] = cosine_similarity(df.loc[:, df.columns.str.startswith('T') | df.columns.str.startswith('A')], playvec.loc[:, playvec.columns.str.startswith('T') | playvec.columns.str.startswith('A')])\n",
    "             df['sim3'] = cosine_similarity(df.loc[:, df.columns.str.startswith('genre')], playvec.loc[:, playvec.columns.str.startswith('genre')])\n",
    "             df['sim4'] = (df['sim']+df['sim2']+df['sim3'])/3\n",
    "             df = df.sort_values(['sim4'], ascending=False,kind='stable').groupby('artist_uri').head(same_art).head(50)\n",
    "             Fresult = pd.concat([Fresult, df], axis=0)\n",
    "             Fresult = Fresult.sort_values(['sim4'], ascending=False,kind='stable')\n",
    "             Fresult.drop_duplicates(subset=['track_uri'], inplace=True,keep='first')\n",
    "             Fresult = Fresult.groupby('artist_uri').head(same_art).head(50)\n",
    "     del test\n",
    "     try:\n",
    "      del df\n",
    "      log.append('Getting Result')\n",
    "     except:\n",
    "         log.append('Getting Result')\n",
    "     if model == 'Model 1':\n",
    "         Fresult = Fresult.sort_values(['sim3', 'sim2', 'sim'],ascending=False,kind='stable')\n",
    "         Fresult.drop_duplicates(subset=['track_uri'], inplace=True,keep='first')\n",
    "         Fresult = Fresult.groupby('artist_uri').head(same_art).track_uri.head(50)\n",
    "     elif model == 'Model 2':\n",
    "         Fresult = Fresult.sort_values(['sim4'], ascending=False,kind='stable')\n",
    "         Fresult.drop_duplicates(subset=['track_uri'], inplace=True,keep='first')\n",
    "         Fresult = Fresult.groupby('artist_uri').head(same_art).track_uri.head(50)\n",
    "     log.append('{} New Tracks Found'.format(len(grow)))\n",
    "     if(len(grow)>=1):\n",
    "        try:\n",
    "            new=pd.read_csv('Data/new_tracks.csv',dtype=dtypes)\n",
    "            new=pd.concat([new, grow], axis=0)\n",
    "            new=new[new.Track_pop >0]\n",
    "            new.drop_duplicates(subset=['track_uri'], inplace=True,keep='last')\n",
    "            new.to_csv('Data/new_tracks.csv',index=False)\n",
    "        except:\n",
    "            grow.to_csv('Data/new_tracks.csv', index=False)\n",
    "     log.append('Model run successfully')\n",
    "    except Exception as e:\n",
    "        log.append(\"Model Failed\")\n",
    "        log.append(e)\n",
    "    return Fresult, log\n",
    "\n",
    "def update_dataset():\n",
    "    col_name= ['track_uri', 'artist_uri', 'album_uri', 'danceability', 'energy', 'key',\n",
    "        'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness',\n",
    "        'liveness', 'valence', 'tempo', 'duration_ms', 'time_signature',\n",
    "        'Track_release_date', 'Track_pop', 'Artist_pop', 'Artist_genres']\n",
    "    dtypes = {'track_uri': 'object', 'artist_uri': 'object', 'album_uri': 'object', 'danceability': 'float16', 'energy': 'float16', 'key': 'float16',\n",
    "               'loudness': 'float16', 'mode': 'float16', 'speechiness': 'float16', 'acousticness': 'float16', 'instrumentalness': 'float16',\n",
    "               'liveness': 'float16', 'valence': 'float16', 'tempo': 'float16', 'duration_ms': 'float32', 'time_signature': 'float16',\n",
    "               'Track_release_date': 'int8', 'Track_pop': 'int8', 'Artist_pop': 'int8', 'Artist_genres': 'object'}\n",
    "    df = pd.read_csv('Data/streamlit.csv',dtype=dtypes)\n",
    "    grow = pd.read_csv('Data/new_tracks.csv',dtype=dtypes)\n",
    "    cur = len(df)\n",
    "    df=pd.concat([df,grow],axis=0)\n",
    "    grow=pd.DataFrame(columns=col_name)\n",
    "    grow.to_csv('Data/new_tracks.csv',index=False)\n",
    "    df=df[df.Track_pop >0]\n",
    "    df.drop_duplicates(subset=['track_uri'],inplace=True,keep='last')\n",
    "    df.dropna(axis=0,inplace=True)\n",
    "    df.to_csv('Data/streamlit.csv',index=False)\n",
    "    return (len(df)-cur)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cad802a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719f8e09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e1292b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e574382b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b3ec1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5f5025",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
